{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ideis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_month = pd.read_csv('data/news/texts_31days.csv', index_col=0)\n",
    "texts_first = pd.read_csv('data/news/texts_12.04-13.04.csv', index_col=0)\n",
    "texts_second = pd.read_csv('data/news/texts_13.04-14.04.csv', index_col=0)\n",
    "texts = pd.concat([texts_month, texts_first, texts_second])\n",
    "texts.index.names = ['url_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using texts.csv to make urls for each url_id\n",
    "def make_urls_df():\n",
    "    texts = pd.read_csv('data/news/texts.csv')\n",
    "\n",
    "    tag_cleaned = texts['tag'].str.split().str.get(0)\n",
    "    texts['tag_cleaned'] = tag_cleaned\n",
    "    texts['url_id'] = texts['url_id'].astype(str)\n",
    "    texts['pagePath'] = '/t/' + texts['tag_cleaned'] + '/' + texts['url_id']\n",
    "\n",
    "    urls = texts.drop(['subtitle', 'tag', 'tag_cleaned'], axis=1)\n",
    "    return urls\n",
    "\n",
    "urls = make_urls_df()\n",
    "urls.dropna(how='any', inplace=True)\n",
    "urls.drop_duplicates(['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def clean_text(text, remove_stopwords=True):\n",
    "    '''Clean the text, with the option to remove stopwords'''\n",
    "    text = text.lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"russian\"))\n",
    "        tokens = [w for w in tokens if not w in stops]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "\n",
    "# PoS tagging\n",
    "from ufal.udpipe import Model, Pipeline\n",
    "modelfile = 'models/udpipe_syntagrus.model'\n",
    "\n",
    "def tag_ud(text, modelfile='udpipe_syntagrus.model'):\n",
    "    model = Model.load(modelfile)\n",
    "    pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')\n",
    "    processed = pipeline.process(text)\n",
    "    output = [l for l in processed.split('\\n') if not l.startswith('#')]\n",
    "    tagged = [w.split('\\t')[2].lower() + '_' + w.split('\\t')[3] for w in output if w]\n",
    "    tagged_propn = []\n",
    "    propn  = []\n",
    "    for t in tagged:\n",
    "        if t.endswith('PROPN'):\n",
    "            if propn:\n",
    "                propn.append(t)\n",
    "            else:\n",
    "                propn = [t]\n",
    "        else:\n",
    "            if len(propn) > 1:\n",
    "                name = '::'.join([x.split('_')[0] for x in propn]) + '_PROPN'\n",
    "                tagged_propn.append(name)\n",
    "            elif len(propn) == 1:\n",
    "                tagged_propn.append(propn[0])\n",
    "            tagged_propn.append(t)\n",
    "            propn = []\n",
    "    return tagged_propn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"models/word2vec/ruscorpora_upos_skipgram_300_5_2018.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_id</th>\n",
       "      <th>title</th>\n",
       "      <th>pagePath</th>\n",
       "      <th>doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Андрей Мягков прооперирован в Германии</td>\n",
       "      <td>/t/новости/20</td>\n",
       "      <td>[-0.0707825, 0.066976, 0.0525985, -0.0433205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Брат Гуса Хиддинка написал песню для России</td>\n",
       "      <td>/t/новости/21</td>\n",
       "      <td>[-0.0603787, 0.0231322, 0.059768, -0.0441762, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>Литва встает на защиту внука Пугачевой</td>\n",
       "      <td>/t/новости/25</td>\n",
       "      <td>[-0.0449517, -0.0494433, 0.0192017, -0.0299023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Dell выпустят смартфон на базе Android</td>\n",
       "      <td>/t/новости/28</td>\n",
       "      <td>[-0.0411953, 0.0155413, 0.000527667, -0.007926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Ребенка ранили после ссоры в маршрутке</td>\n",
       "      <td>/t/новости/29</td>\n",
       "      <td>[-0.0481922, 0.0016745, -0.0038685, -0.0150153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Владимиру Путину изготовили личный биоЧИП</td>\n",
       "      <td>/t/новости/34</td>\n",
       "      <td>[-0.000262, 0.0151814, 0.0158028, -0.000719999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>Перед смертью Япончика соборовал священник</td>\n",
       "      <td>/t/новости/42</td>\n",
       "      <td>[-0.0715463, -0.0621635, 0.0723903, -0.052593,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>300 км/ч на шоссе общего пользования</td>\n",
       "      <td>/t/новости/44</td>\n",
       "      <td>[-0.020147, -0.02574, 0.0193276, -0.027425, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49</td>\n",
       "      <td>Чубайс платит 4,3 млрд за счетчики для нефти</td>\n",
       "      <td>/t/новости/49</td>\n",
       "      <td>[-0.0354266, 0.0628282, -0.0084598, 0.031462, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61</td>\n",
       "      <td>Карикатурист поймал вора за 15 минут</td>\n",
       "      <td>/t/новости/61</td>\n",
       "      <td>[-0.0745085, -0.021892, 0.0608343, -0.0498217,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_id                                         title       pagePath  \\\n",
       "0      20        Андрей Мягков прооперирован в Германии  /t/новости/20   \n",
       "1      21   Брат Гуса Хиддинка написал песню для России  /t/новости/21   \n",
       "2      25        Литва встает на защиту внука Пугачевой  /t/новости/25   \n",
       "3      28        Dell выпустят смартфон на базе Android  /t/новости/28   \n",
       "4      29        Ребенка ранили после ссоры в маршрутке  /t/новости/29   \n",
       "5      34     Владимиру Путину изготовили личный биоЧИП  /t/новости/34   \n",
       "6      42    Перед смертью Япончика соборовал священник  /t/новости/42   \n",
       "7      44          300 км/ч на шоссе общего пользования  /t/новости/44   \n",
       "8      49  Чубайс платит 4,3 млрд за счетчики для нефти  /t/новости/49   \n",
       "9      61          Карикатурист поймал вора за 15 минут  /t/новости/61   \n",
       "\n",
       "                                             doc2vec  \n",
       "0  [-0.0707825, 0.066976, 0.0525985, -0.0433205, ...  \n",
       "1  [-0.0603787, 0.0231322, 0.059768, -0.0441762, ...  \n",
       "2  [-0.0449517, -0.0494433, 0.0192017, -0.0299023...  \n",
       "3  [-0.0411953, 0.0155413, 0.000527667, -0.007926...  \n",
       "4  [-0.0481922, 0.0016745, -0.0038685, -0.0150153...  \n",
       "5  [-0.000262, 0.0151814, 0.0158028, -0.000719999...  \n",
       "6  [-0.0715463, -0.0621635, 0.0723903, -0.052593,...  \n",
       "7  [-0.020147, -0.02574, 0.0193276, -0.027425, -0...  \n",
       "8  [-0.0354266, 0.0628282, -0.0084598, 0.031462, ...  \n",
       "9  [-0.0745085, -0.021892, 0.0608343, -0.0498217,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc2vec for every news title\n",
    "vec_dim = 300\n",
    "\n",
    "def create_average_vec(doc):\n",
    "    average = np.zeros((vec_dim,), dtype='float32')\n",
    "    num_words = 0.\n",
    "    for word in doc:\n",
    "        if word in word2vec_model:\n",
    "            average = np.add(average, word2vec_model[word])\n",
    "            num_words += 1.\n",
    "    if num_words != 0.:\n",
    "        average = np.divide(average, num_words)\n",
    "    return average\n",
    "\n",
    "\n",
    "def create_doc2vec(text):\n",
    "    text = str(text)\n",
    "    processed_text = clean_text(text)\n",
    "    processed_ud = tag_ud(text=processed_text, modelfile=modelfile)\n",
    "    vec = create_average_vec(processed_ud)\n",
    "    return vec\n",
    "\n",
    "urls['doc2vec'] = urls['title'].apply(create_doc2vec)\n",
    "urls.to_csv('data/news/unique_titles_urls_with_doc2vec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "def make_df(start_time, end_time):\n",
    "    timestamps = sorted(os.listdir('data/news/timestamps'))\n",
    "    start_timestamp, end_timestamp = make_timestamps_from_datetime(start_time, end_time, timestamps)\n",
    "    interval = make_interval(start_timestamp, end_timestamp, timestamps)\n",
    "    with ZipFile('data/news/timestamps.zip') as timestamps_zip:\n",
    "        df_list = [pd.read_csv(timestamps_zip.open(\"timestamps/\" + file), header=None, names=['fullVisitorId', 'url_id', 'visitStartTime']) for file in interval]\n",
    "    df = pd.concat(df_list)\n",
    "    labels, levels = pd.factorize(df['fullVisitorId'])\n",
    "    df['user_id'] = labels\n",
    "    return df\n",
    "\n",
    "\n",
    "# first = 12/03/2017 07:00:00, last = 14/04/2017 11:11:29 1491818423 1491991225\n",
    "def make_timestamps_from_datetime(start_time, end_time, timestamps):\n",
    "    if start_time == 'first':\n",
    "        start_timestamp = timestamps[0]\n",
    "    else:\n",
    "        start_datetime = datetime.strptime(start_time, '%d/%m/%Y %H:%M:%S')\n",
    "        start_timestamp = (start_datetime - datetime(1970, 1, 1)).total_seconds()\n",
    "        \n",
    "    if end_time == 'last':\n",
    "        end_timestamp = timestamps[-1]\n",
    "    else:\n",
    "        end_datetime = datetime.strptime(end_time, '%d/%m/%Y %H:%M:%S')\n",
    "        end_timestamp = (end_datetime - datetime(1970, 1, 1)).total_seconds()\n",
    "    return (start_timestamp, end_timestamp)\n",
    "\n",
    "\n",
    "def make_interval(start_timestamp, end_timestamp, timestamps):\n",
    "    start_timestamp = str(start_timestamp)\n",
    "    end_timestamp = str(end_timestamp)\n",
    "    interval = [t for t in timestamps if t >= start_timestamp and t <= end_timestamp]\n",
    "    return interval\n",
    "\n",
    "\n",
    "def merge_df(df, urls):\n",
    "    df['fullVisitorId'] = df['fullVisitorId'].astype(str)\n",
    "    urls['url_id'] = urls['url_id'].astype(int)\n",
    "    urls['title'] = urls['title'].astype(str)\n",
    "    \n",
    "    df_result = pd.merge(df, urls, on='url_id', how='left')\n",
    "\n",
    "    labels, levels = pd.factorize(df_result['url_id'])\n",
    "    df_result['url_id'] = labels\n",
    "    df_result.set_index(['user_id', 'url_id'], inplace=True)\n",
    "    df_result.sort_index(inplace=True)\n",
    "    df_result.dropna(how='any',inplace=True)\n",
    "    df_result.drop_duplicates(inplace=True)\n",
    "    return df_result\n",
    "\n",
    "\n",
    "df = make_df('16/03/2017 9:00:00', '16/03/2017 10:00:00')\n",
    "df_result = merge_df(df, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 0 entries\n",
      "Data columns (total 5 columns):\n",
      "fullVisitorId     0 non-null object\n",
      "visitStartTime    0 non-null int64\n",
      "title             0 non-null object\n",
      "pagePath          0 non-null object\n",
      "doc2vec           0 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 684.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>title</th>\n",
       "      <th>pagePath</th>\n",
       "      <th>doc2vec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>url_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fullVisitorId, visitStartTime, title, pagePath, doc2vec]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>title</th>\n",
       "      <th>pagePath</th>\n",
       "      <th>doc2vec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>url_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fullVisitorId, visitStartTime, title, pagePath, doc2vec]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_result.info())\n",
    "display(df_result.head(20))\n",
    "display(df_result.tail(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

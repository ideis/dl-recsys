{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1620779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pagePath</th>\n",
       "      <th>country</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>294703</td>\n",
       "      <td>88b526ee2d655644615e5c18fbeb7c5c</td>\n",
       "      <td>1529661427</td>\n",
       "      <td>/</td>\n",
       "      <td>United States</td>\n",
       "      <td>[{\"name\": \"/Arts &amp; Entertainment\", \"confidence...</td>\n",
       "      <td>Breaking news, independent China news</td>\n",
       "      <td>5702478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id                     fullVisitorId   timestamp pagePath  \\\n",
       "0        0   294703  88b526ee2d655644615e5c18fbeb7c5c  1529661427        /   \n",
       "\n",
       "         country                                           category  \\\n",
       "0  United States  [{\"name\": \"/Arts & Entertainment\", \"confidence...   \n",
       "\n",
       "                                   title   scores  \n",
       "0  Breaking news, independent China news  5702478  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import spacy\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "df1 = pd.read_csv('data/news_dataset.csv')\n",
    "print(df1.shape[0])\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1620779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pagePath</th>\n",
       "      <th>country</th>\n",
       "      <th>scores</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>vector</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88b526ee2d655644615e5c18fbeb7c5c</td>\n",
       "      <td>1529661427</td>\n",
       "      <td>/</td>\n",
       "      <td>United States</td>\n",
       "      <td>5702478</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"name\": \"/Arts &amp; Entertainment\", \"confidence...</td>\n",
       "      <td>Breaking news, independent China news</td>\n",
       "      <td>[-0.22008367, 0.48308718, -0.055601496, 0.0240...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88b526ee2d655644615e5c18fbeb7c5c</td>\n",
       "      <td>1529671360</td>\n",
       "      <td>/</td>\n",
       "      <td>United States</td>\n",
       "      <td>5702478</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"name\": \"/Arts &amp; Entertainment\", \"confidence...</td>\n",
       "      <td>Breaking news, independent China news</td>\n",
       "      <td>[-0.22008367, 0.48308718, -0.055601496, 0.0240...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fullVisitorId   timestamp pagePath        country  \\\n",
       "0  88b526ee2d655644615e5c18fbeb7c5c  1529661427        /  United States   \n",
       "1  88b526ee2d655644615e5c18fbeb7c5c  1529671360        /  United States   \n",
       "\n",
       "    scores  item_id                                           category  \\\n",
       "0  5702478        1  [{\"name\": \"/Arts & Entertainment\", \"confidence...   \n",
       "1  5702478        1  [{\"name\": \"/Arts & Entertainment\", \"confidence...   \n",
       "\n",
       "                                   title  \\\n",
       "0  Breaking news, independent China news   \n",
       "1  Breaking news, independent China news   \n",
       "\n",
       "                                              vector  user_id  \n",
       "0  [-0.22008367, 0.48308718, -0.055601496, 0.0240...        0  \n",
       "1  [-0.22008367, 0.48308718, -0.055601496, 0.0240...        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reindex(df1):\n",
    "    nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner', 'textcat'])\n",
    "    unique_items = df1.drop_duplicates('pagePath').copy().reset_index()\n",
    "    unique_items.drop(['user_id','item_id','fullVisitorId','timestamp','country','scores', 'index'], axis=1, inplace=True)\n",
    "    unique_items = unique_items.reset_index().rename(columns={\"index\": \"item_id\"})\n",
    "    unique_items[\"item_id\"] = unique_items[\"item_id\"] + 1\n",
    "    unique_items['vector'] = unique_items['title'].apply(lambda doc: nlp(doc).vector)\n",
    "\n",
    "    df_result = pd.merge(df1.drop(['user_id','item_id','title','category'], axis=1)\n",
    "                         , unique_items, on='pagePath', how='left')\n",
    "\n",
    "    unique_users = df1.drop_duplicates('fullVisitorId').copy().reset_index()\n",
    "    unique_users = unique_users[['fullVisitorId']].reset_index().rename(columns={\"index\": \"user_id\"})\n",
    "    df_result = pd.merge(df_result, unique_users, on='fullVisitorId', how='left')\n",
    "    return df_result, unique_items, unique_users\n",
    "\n",
    "df_result, unique_items, unique_users = reindex(df1)\n",
    "print(df_result.shape[0])\n",
    "df_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1529661427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1529671360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1529660632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   timestamp\n",
       "0        0        1  1529661427\n",
       "1        0        1  1529671360\n",
       "2        1        1  1529660632"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_result[['user_id', 'item_id', 'timestamp']]\n",
    "# df['timestamp'] = df['timestamp'].apply(datetime.fromtimestamp)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:\n",
      "22/06/2018 00:00:00\n",
      "End time:\n",
      "28/06/2018 23:59:59\n",
      "Train engagements: 67710\n",
      "Train #users: 41060\n",
      "Train #items: 1681\n",
      "Test engagements: 13343\n",
      "Test #users: 11617\n",
      "Test #items: 674\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "def make_interval(start_time, end_time, timestamps):\n",
    "    if start_time == 'first':\n",
    "        start_timestamp = timestamps[0]\n",
    "    else:\n",
    "        start_datetime = datetime.strptime(start_time, '%d/%m/%Y %H:%M:%S')\n",
    "        start_timestamp = (start_datetime - datetime(1970, 1, 1)).total_seconds()\n",
    "\n",
    "    if end_time == 'last':\n",
    "        end_timestamp = timestamps[-1]\n",
    "    else:\n",
    "        end_datetime = datetime.strptime(end_time, '%d/%m/%Y %H:%M:%S')\n",
    "        end_timestamp = (end_datetime - datetime(1970, 1, 1)).total_seconds()\n",
    "\n",
    "    return df[(df['timestamp'] > start_timestamp) & (df['timestamp'] < end_timestamp)]\n",
    "\n",
    "df.sort_values(by='timestamp', inplace=True)\n",
    "print('Start time:')\n",
    "print(datetime.fromtimestamp(df.iloc[0][2], tz=timezone('US/Eastern')).strftime('%d/%m/%Y %H:%M:%S'))\n",
    "print('End time:')\n",
    "print(datetime.fromtimestamp(df.iloc[-1][2], tz=timezone('US/Eastern')).strftime('%d/%m/%Y %H:%M:%S'))\n",
    "\n",
    "# choose date between 2018-06-22 00:00:00 and 2018-06-28 23:59:59\n",
    "train = make_interval('22/06/2018 10:00:00', '22/06/2018 18:00:00', df.timestamp)\n",
    "test  = make_interval('22/06/2018 18:00:00', '22/06/2018 19:00:00', df.timestamp)\n",
    "\n",
    "print(f'Train engagements: {train.shape[0]}')\n",
    "print(f'Train #users: {len(train.user_id.unique())}')\n",
    "print(f'Train #items: {len(train.item_id.unique())}')\n",
    "print(f'Test engagements: {test.shape[0]}')\n",
    "print(f'Test #users: {len(test.user_id.unique())}')\n",
    "print(f'Test #items: {len(test.item_id.unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Interactions dataset (105984 users x 2401 items x 67710 interactions)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotlight.interactions import Interactions\n",
    "\n",
    "train_interactions = Interactions(train['user_id'].values, train['item_id'].values, timestamps = train['timestamp'].values)\n",
    "test_interactions = Interactions(test['user_id'].values, test['item_id'].values, timestamps = test['timestamp'].values)\n",
    "train_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "# model = ImplicitFactorizationModel(n_iter=10, embedding_dim=10, loss='adaptive_hinge', \n",
    "#                                    learning_rate=0.2, use_cuda='CUDA')\n",
    "# model.fit(train_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotlight.evaluation import precision_recall_score\n",
    "# from spotlight.evaluation import mrr_score\n",
    "# k = 10\n",
    "# precision_recall = precision_recall_score(model, test_interactions, k=k)\n",
    "\n",
    "# print(f'Precision@{k}: {precision_recall[0].mean()}')\n",
    "# print(f'Recall@{k}: {precision_recall[1].mean()}')\n",
    "# mrr = mrr_score(model, test_interactions)\n",
    "# mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Precision@10: 0.06753034346216752 Recall@10: 0.6657698897756573\n",
    "# 100 Precision@10: 0.08117414134458123 Recall@10: 0.8010888189312052\n",
    "# 1000 Precision@10: 0.08268055435998968 Recall@10: 0.8156248847132896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(4918, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embedding = np.vstack([[0]*300]+unique_items['vector'].tolist())\n",
    "torch_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(text_embedding))\n",
    "torch_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(4918, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f852235eba0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences = train_interactions.to_sequence(5)\n",
    "test_sequences = test_interactions.to_sequence(5)\n",
    "\n",
    "from spotlight.datasets.synthetic import generate_sequential\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "from spotlight.evaluation import sequence_precision_recall_score, _get_precision_recall\n",
    "from spotlight.sequence.representations import CNNNet, LSTMNet\n",
    "from spotlight.layers import ScaledEmbedding, ZeroEmbedding\n",
    "# from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from implicit import ImplicitSequenceModel\n",
    "\n",
    "\n",
    "PADDING_IDX = 0\n",
    "class LSTMNet1(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=32,\n",
    "                 item_embedding_layer=None, sparse=False):\n",
    "\n",
    "        super(LSTMNet1, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if item_embedding_layer is not None:\n",
    "            self.item_embeddings = item_embedding_layer\n",
    "        else:\n",
    "            self.item_embeddings = ScaledEmbedding(num_items, embedding_dim,\n",
    "                                                   padding_idx=PADDING_IDX,\n",
    "                                                   sparse=sparse)\n",
    "        print(self.item_embeddings)\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1, sparse=sparse,\n",
    "                                         padding_idx=PADDING_IDX)\n",
    "\n",
    "        self.lstm = nn.LSTM(batch_first=True,\n",
    "                            input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim)\n",
    "\n",
    "    def user_representation(self, item_sequences):\n",
    "\n",
    "        # Make the embedding dimension the channel dimension\n",
    "        sequence_embeddings = (self.item_embeddings(item_sequences).permute(0, 2, 1))\n",
    "        # Add a trailing dimension of 1\n",
    "        sequence_embeddings = (sequence_embeddings.unsqueeze(3))\n",
    "        # Pad it with zeros from left\n",
    "        sequence_embeddings = (F.pad(sequence_embeddings, (0, 0, 1, 0)).squeeze(3))\n",
    "        sequence_embeddings = sequence_embeddings.permute(0, 2, 1)\n",
    "\n",
    "        user_representations, _ = self.lstm(sequence_embeddings)\n",
    "        user_representations = user_representations.permute(0, 2, 1)\n",
    "\n",
    "        return user_representations[:, :, :-1], user_representations[:, :, -1]\n",
    "\n",
    "    def forward(self, user_representations, targets):\n",
    "        target_embedding = (self.item_embeddings(targets).permute(0, 2, 1).squeeze())\n",
    "        target_bias = self.item_biases(targets).squeeze()\n",
    "\n",
    "        dot = ((user_representations * target_embedding).sum(1).squeeze())\n",
    "        return target_bias + dot\n",
    "\n",
    "from spotlight.layers import BloomEmbedding, ScaledEmbedding\n",
    "embedding = BloomEmbedding(unique_items.shape[0]+1,\n",
    "                               32,\n",
    "                               compression_ratio=1.,\n",
    "                               num_hash_functions=2)\n",
    "\n",
    "lstm1 = LSTMNet1(unique_items.shape[0]+1, embedding_dim = 300, item_embedding_layer = torch_embedding)\n",
    "lstm1.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "smodel = ImplicitSequenceModel(n_iter=20, batch_size = 10000, embedding_dim=32,\n",
    "                              representation=lstm1, num_negative_samples = 5,\n",
    "                              loss='adaptive_hinge', use_cuda=True) \n",
    "\n",
    "smodel.fit(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mrr = sequence_mrr_score(smodel, test_interactions.to_sequence(5), exclude_preceding = False)\n",
    "# mrr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.08190639759553459\n",
      "Recall@10: 0.8190639759553456\n"
     ]
    }
   ],
   "source": [
    "def sequence_precision_recall_score1(model, test, k=10, exclude_preceding=False):\n",
    "    sequences = test.sequences[:, :-1]\n",
    "    targets = test.sequences[:, -1:]\n",
    "    precision_recalls = []\n",
    "    for i in range(len(sequences)):\n",
    "        predictions = -model.predict(sequences[i])\n",
    "        if exclude_preceding:\n",
    "            predictions[sequences[i]] = FLOAT_MAX\n",
    "\n",
    "        predictions = predictions.argsort()[:k]\n",
    "        precision_recall = _get_precision_recall(predictions, targets[i], k)\n",
    "        precision_recalls.append(precision_recall)\n",
    "\n",
    "    precision = np.array(precision_recalls)[:, 0]\n",
    "    recall = np.array(precision_recalls)[:, 1]\n",
    "    return precision, recall\n",
    "\n",
    "k=10\n",
    "precision_recall = sequence_precision_recall_score1(smodel, test_sequences, k = k)\n",
    "print(f'Precision@{k}: {precision_recall[0].mean()}')\n",
    "print(f'Recall@{k}: {precision_recall[1].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpr\n",
    "# 'cnn'\n",
    "# 10 Precision@10: 0.01094031773293259 Recall@10: 0.10940317732932589\n",
    "# 100 Precision@10: 0.08146844139115501 Recall@10: 0.81468441391155\n",
    "# 'lstm'\n",
    "# 100 Precision@10: 0.07891799055388579 Recall@10: 0.7891799055388579\n",
    "# 1000 Precision@10: 0.0802060970373551 Recall@10: 0.8020609703735508\n",
    "# adaptive_hinge\n",
    "# 10 Precision@10: 0.08036066981537142 Recall@10: 0.803606698153714\n",
    "# 20 Precision@10: 0.08182911120652642 Recall@10: 0.8182911120652641\n",
    "# 30 Precision@10: 0.08175182481751826 Recall@10: 0.8175182481751825\n",
    "# text embedding\n",
    "# 10 Precision@10: 0.08177758694718765  Recall@10: 0.8177758694718763\n",
    "# 20 Precision@10: 0.08190639759553459  Recall@10: 0.8190639759553456\n",
    "# 30 Precision@10: 0.08186346071275227 Recall@10: 0.8186346071275226\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
